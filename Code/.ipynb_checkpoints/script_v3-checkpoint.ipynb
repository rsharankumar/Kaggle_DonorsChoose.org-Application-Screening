{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resources.csv', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../Input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "resources = pd.read_csv(\"../input/resources.csv\")\n",
    "train = train.sort_values(by=\"project_submitted_datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved']\n",
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects']\n"
     ]
    }
   ],
   "source": [
    "# print sample rows from train and test dataset\n",
    "#print(train.head())\n",
    "#print(test.head())\n",
    "#printing column names of train and test datasets\n",
    "print(train.columns.values)\n",
    "print(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "f592a49e-f0d0-4e26-ae59-5bfe7434248b",
    "_uuid": "72a58c08a2d4498e4628af5e344dafb4bee99f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'description' 'quantity' 'price']\n",
      "        id                                        description  quantity  \\\n",
      "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
      "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
      "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
      "3  p069063  Dixon Ticonderoga Wood-Cased #2 HB Pencils, Bo...         2   \n",
      "4  p069063  EDUCATIONAL INSIGHTS FLUORESCENT LIGHT FILTERS...         3   \n",
      "\n",
      "    price  \n",
      "0  149.00  \n",
      "1   14.95  \n",
      "2    8.45  \n",
      "3   13.59  \n",
      "4   24.95  \n"
     ]
    }
   ],
   "source": [
    "# Checking the resources datasets\n",
    "print(resources.columns.values)\n",
    "print(resources.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ids in Resources: 260115\n",
      "Count ids in Resources: 1541272\n",
      "Unique ids in train: 182080\n",
      "Count ids in train: 182080\n",
      "Unique ids in test: 78035\n",
      "Count ids in test: 78035\n",
      "Unique ids in test+train: 260115\n"
     ]
    }
   ],
   "source": [
    "# Performing basic count checks\n",
    "print(\"Unique ids in Resources:\", resources['id'].nunique())\n",
    "print(\"Count ids in Resources:\", resources['id'].count())\n",
    "print(\"Unique ids in train:\", train['id'].nunique())\n",
    "print(\"Count ids in train:\", train['id'].count())\n",
    "print(\"Unique ids in test:\", test['id'].nunique())\n",
    "print(\"Count ids in test:\", test['id'].count())\n",
    "print(\"Unique ids in test+train:\", train['id'].nunique() + test['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "1b8a0111-65da-49d0-8aa1-14db0c4c8600",
    "_uuid": "fd0e3b2ceaffa53a0704835e80b5e4af80150e97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To check the overlap between the teachers_id between the train and the test\n",
    "teachers_train = list(set(train.teacher_id.values))\n",
    "teachers_test = list(set(test.teacher_id.values))\n",
    "inter = set(teachers_train).intersection(teachers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "788ca21e-68b1-4fa3-81be-bacfb409719c",
    "_uuid": "5c66ea49dc1dbe24415c5b7f0fafa4c493eec321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number teachers train : 104414, Number teachers test : 55508, Overlap : 27789 \n"
     ]
    }
   ],
   "source": [
    "print(\"Number teachers train : %s, Number teachers test : %s, Overlap : %s \"%(len(teachers_train), len(teachers_test), len(inter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "124ee5e2-d7c0-46ce-bc54-5c3dc6a74b3f",
    "_uuid": "f808ed8bd3e0860f30b0c3ea50061bae31c22c82",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_cols = ['project_subject_categories', 'project_subject_subcategories',\n",
    "       'project_title', 'project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4', 'project_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "62aaa5f9-6313-44cb-9401-03b4f7d2a103",
    "_uuid": "69d9a051b7cbf0e542480ac6c432f2a575ec5b77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/mmi333/beat-the-benchmark-with-one-feature\n",
    "resources['total_price'] = resources.quantity * resources.price\n",
    "\n",
    "mean_total_price = pd.DataFrame(resources.groupby('id').total_price.mean()) \n",
    "sum_total_price = pd.DataFrame(resources.groupby('id').total_price.sum()) \n",
    "count_total_price = pd.DataFrame(resources.groupby('id').total_price.count())\n",
    "mean_total_price['id'] = mean_total_price.index\n",
    "sum_total_price['id'] = mean_total_price.index\n",
    "count_total_price['id'] = mean_total_price.index\n",
    "\n",
    "def create_features(df):\n",
    "    \n",
    "\n",
    "    df = pd.merge(df, mean_total_price, on='id')\n",
    "    df = pd.merge(df, sum_total_price, on='id')\n",
    "    df = pd.merge(df, count_total_price, on='id')\n",
    "    df['year'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[0])\n",
    "    df['month'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[1])\n",
    "    for col in char_cols:\n",
    "        df[col] = df[col].fillna(\"NA\")\n",
    "    df['text'] = df.apply(lambda x: \" \".join(x[col] for col in char_cols), axis=1)\n",
    "    return df\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'total_price_x' 'total_price_y' 'total_price' 'year' 'month' 'text'\n",
      " 'teacher_prefix_hash' 'school_state_hash' 'year_hash' 'month_hash'\n",
      " 'project_grade_category_hash' 'project_subject_categories_hash'\n",
      " 'project_subject_subcategories_hash']\n"
     ]
    }
   ],
   "source": [
    "print(train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-1796fb38c293>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0messay_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_polarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtextblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "### CODE TO ADD NEW FEATURES THAT HAS GOOD CORRELATION WITH THE SELECTION RATE#\n",
    "###############################################################################\n",
    "# Columns that has the project essay text\n",
    "essay_cols = ['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']\n",
    "# creating a separate column to hold the project essay\n",
    "train['essay_text'] = train.apply(lambda x: \" \".join(x[col] for col in essay_cols), axis=1)\n",
    "test['essay_text'] = test.apply(lambda x: \" \".join(x[col] for col in essay_cols), axis=1)\n",
    "\n",
    "from textblob import TextBlob\n",
    "def get_polarity(text):\n",
    "    textblob = TextBlob(unicode(text, 'utf-8'))\n",
    "    pol = textblob.sentiment.polarity\n",
    "    return round(pol,3)\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    textblob = TextBlob(unicode(text, 'utf-8'))\n",
    "    subj = textblob.sentiment.subjectivity\n",
    "    return round(subj,3)\n",
    "\n",
    "train['polarity'] = train['essay_text'].apply(get_polarity)\n",
    "train['subjectivity'] = train['essay_text'].apply(get_subjectivity)\n",
    "test['polarity'] = test['essay_text'].apply(get_polarity)\n",
    "test['subjectivity'] = test['essay_text'].apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  One Two Three\n",
      "0  1A  2B    3C\n",
      "1  4A  5B    6C\n",
      "2  7A  8B    9C\n",
      "  One Two Three      text\n",
      "0  1A  2B    3C  1A 2B 3C\n",
      "1  4A  5B    6C  4A 5B 6C\n",
      "2  7A  8B    9C  7A 8B 9C\n"
     ]
    }
   ],
   "source": [
    "# Testing the test columns merging logic\n",
    "# Creating a sample data frame\n",
    "df_test = pd.DataFrame([['1A', '2B', '3C'], ['4A', '5B', '6C'], ['7A', '8B', '9C']])\n",
    "df_test.columns = ['One', 'Two', 'Three']\n",
    "print(df_test)\n",
    "# Specifying the columns to be merged\n",
    "char1_cols = ['One', 'Two', 'Three']\n",
    "# Merging the columns\n",
    "df_test['text'] = df_test.apply(lambda x: \" \".join(x[col] for col in char1_cols), axis=1)\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_price        596\n",
      "id             p146022\n",
      "Name: p146022, dtype: object\n",
      "total_price        596\n",
      "id             p146022\n",
      "Name: p146022, dtype: object\n",
      "total_price          1\n",
      "id             p146022\n",
      "Name: p146022, dtype: object\n",
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p146022  f91a89d2b72a0f5ee14cd98bd8741fc2            Ms.           CA   \n",
      "1  p244738  64ef8a335f7206366c52c39f5bfd09b7            Ms.           TX   \n",
      "2  p070708  1f802ff6be7973fb3624332e10549ed4           Mrs.           CA   \n",
      "3  p083729  f72fac3c6011b17ad5b2037dfd18cd0b        Teacher           CA   \n",
      "4  p205479  2bf07ba08945e5d8b2a3f269b2b3cfe5           Mrs.           CA   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-04-27 00:03:38             Grades 6-8   \n",
      "1        2016-04-27 00:04:09          Grades PreK-2   \n",
      "2        2016-04-27 00:15:39          Grades PreK-2   \n",
      "3        2016-04-27 00:20:33          Grades PreK-2   \n",
      "4        2016-04-27 00:27:36          Grades PreK-2   \n",
      "\n",
      "            project_subject_categories  \\\n",
      "0                       Math & Science   \n",
      "1  Literacy & Language, Math & Science   \n",
      "2                       Math & Science   \n",
      "3  Literacy & Language, Math & Science   \n",
      "4                       Math & Science   \n",
      "\n",
      "             project_subject_subcategories  \\\n",
      "0                         Applied Sciences   \n",
      "1           Foreign Languages, Mathematics   \n",
      "2                              Mathematics   \n",
      "3                    Literacy, Mathematics   \n",
      "4  Applied Sciences, Health & Life Science   \n",
      "\n",
      "                                     project_title  \\\n",
      "0                         Robotics and Programming   \n",
      "1           Help Us Finish Our 1st Year In School!   \n",
      "2           Common Core Math Tools for Young Minds   \n",
      "3  Bring 21st Century Resources Into Kindergarten!   \n",
      "4     Engineering STEAM into the Primary Classroom   \n",
      "\n",
      "                                     project_essay_1  \\\n",
      "0  I love giving my students experiences. A new e...   \n",
      "1  We are getting closer to the end of the year, ...   \n",
      "2  Our classroom is an engaging, vibrant, and div...   \n",
      "3  My students are young children eager to engage...   \n",
      "4  I have been fortunate enough to use the Fairy ...   \n",
      "\n",
      "                 ...                  year month  \\\n",
      "0                ...                  2016    04   \n",
      "1                ...                  2016    04   \n",
      "2                ...                  2016    04   \n",
      "3                ...                  2016    04   \n",
      "4                ...                  2016    04   \n",
      "\n",
      "                                                text teacher_prefix_hash  \\\n",
      "0  Math & Science Applied Sciences Robotics and P...                2741   \n",
      "1  Literacy & Language, Math & Science Foreign La...                2741   \n",
      "2  Math & Science Mathematics Common Core Math To...               14947   \n",
      "3  Literacy & Language, Math & Science Literacy, ...                3494   \n",
      "4  Math & Science Applied Sciences, Health & Life...               14947   \n",
      "\n",
      "   school_state_hash  year_hash  month_hash  project_grade_category_hash  \\\n",
      "0                165      11468       14366                        10629   \n",
      "1               1867      11468       14366                         9549   \n",
      "2                165      11468       14366                         9549   \n",
      "3                165      11468       14366                         9549   \n",
      "4                165      11468       14366                         9549   \n",
      "\n",
      "   project_subject_categories_hash project_subject_subcategories_hash  \n",
      "0                            10268                              11993  \n",
      "1                            13720                               9810  \n",
      "2                            10268                              13911  \n",
      "3                            13720                               7221  \n",
      "4                            10268                               7017  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p146022  f91a89d2b72a0f5ee14cd98bd8741fc2            Ms.           CA   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-04-27 00:03:38             Grades 6-8   \n",
      "\n",
      "  project_subject_categories project_subject_subcategories  \\\n",
      "0             Math & Science              Applied Sciences   \n",
      "\n",
      "              project_title  \\\n",
      "0  Robotics and Programming   \n",
      "\n",
      "                                     project_essay_1  \\\n",
      "0  I love giving my students experiences. A new e...   \n",
      "\n",
      "                 ...                  year month  \\\n",
      "0                ...                  2016    04   \n",
      "\n",
      "                                                text teacher_prefix_hash  \\\n",
      "0  Math & Science Applied Sciences Robotics and P...                2741   \n",
      "\n",
      "   school_state_hash  year_hash  month_hash  project_grade_category_hash  \\\n",
      "0                165      11468       14366                        10629   \n",
      "\n",
      "   project_subject_categories_hash project_subject_subcategories_hash  \n",
      "0                            10268                              11993  \n",
      "\n",
      "[1 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking the numeric values\n",
    "print(mean_total_price.loc['p146022',:])\n",
    "print(sum_total_price.loc['p146022',:])\n",
    "print(count_total_price.loc['p146022',:])\n",
    "print(train.head())\n",
    "\n",
    "# Checking the text columns\n",
    "print(train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "cd94beed-d105-459e-920a-7e2bd041520b",
    "_uuid": "e3d6230e3bf65049b2d58272d53d01323e37bbf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'total_price_x' 'total_price_y' 'total_price' 'year' 'month' 'text'\n",
      " 'teacher_prefix_hash' 'school_state_hash' 'year_hash' 'month_hash'\n",
      " 'project_grade_category_hash' 'project_subject_categories_hash'\n",
      " 'project_subject_subcategories_hash']\n",
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'total_price_x'\n",
      " 'total_price_y' 'total_price' 'year' 'month' 'text' 'teacher_prefix_hash'\n",
      " 'school_state_hash' 'year_hash' 'month_hash' 'project_grade_category_hash'\n",
      " 'project_subject_categories_hash' 'project_subject_subcategories_hash']\n"
     ]
    }
   ],
   "source": [
    "# With Newly added columns\n",
    "print(train.columns.values)\n",
    "print(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "7742c5d2-5d8e-4965-9a1c-a2c2a0164bee",
    "_uuid": "0f84509b4bfbe8555e3f88df35f04ee57c20c435",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = [\"teacher_prefix\", \"school_state\", \"year\", \"month\", \"project_grade_category\", \"project_subject_categories\", \"project_subject_subcategories\"]\n",
    "#\"teacher_id\", \n",
    "num_features = [\"teacher_number_of_previously_posted_projects\", \"total_price_x\", \"total_price_y\", \"total_price\"]\n",
    "cat_features_hash = [col+\"_hash\" for col in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "6f9594b5-155e-47a5-b6f5-24d3ac49ffee",
    "_uuid": "a2c15bc8a55fcb1c571cfbe6b7062fa2294e581f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_size=15000#0\n",
    "def feature_hash(df, max_size=max_size):\n",
    "    for col in cat_features:\n",
    "        df[col+\"_hash\"] = df[col].apply(lambda x: hash(x)%max_size)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "ccd45300-40ac-4894-b14a-cd5b026aacac",
    "_uuid": "4dc775237b3a4ca40458919bbe9488b0c295fb10",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hashing converts the categorical columns to numerical values\n",
    "train = feature_hash(train)\n",
    "test = feature_hash(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'total_price_x' 'total_price_y' 'total_price' 'year' 'month' 'text'\n",
      " 'teacher_prefix_hash' 'school_state_hash' 'year_hash' 'month_hash'\n",
      " 'project_grade_category_hash' 'project_subject_categories_hash'\n",
      " 'project_subject_subcategories_hash']\n",
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p146022  f91a89d2b72a0f5ee14cd98bd8741fc2            Ms.           CA   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-04-27 00:03:38             Grades 6-8   \n",
      "\n",
      "  project_subject_categories project_subject_subcategories  \\\n",
      "0             Math & Science              Applied Sciences   \n",
      "\n",
      "              project_title  \\\n",
      "0  Robotics and Programming   \n",
      "\n",
      "                                     project_essay_1  \\\n",
      "0  I love giving my students experiences. A new e...   \n",
      "\n",
      "                 ...                  year month  \\\n",
      "0                ...                  2016    04   \n",
      "\n",
      "                                                text teacher_prefix_hash  \\\n",
      "0  Math & Science Applied Sciences Robotics and P...                2741   \n",
      "\n",
      "   school_state_hash  year_hash  month_hash  project_grade_category_hash  \\\n",
      "0                165      11468       14366                        10629   \n",
      "\n",
      "   project_subject_categories_hash project_subject_subcategories_hash  \n",
      "0                            10268                              11993  \n",
      "\n",
      "[1 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.columns.values)\n",
    "print(train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "dddf070f-e7fb-40e5-aba2-71c88c95f79e",
    "_uuid": "012e5a280f975a7a85eaa5911f8c158447138a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Math & Science Applied Sciences Robotics and P...\n",
      "1    Literacy & Language, Math & Science Foreign La...\n",
      "2    Math & Science Mathematics Common Core Math To...\n",
      "3    Literacy & Language, Math & Science Literacy, ...\n",
      "4    Math & Science Applied Sciences, Health & Life...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Printing sample text column\n",
    "print(train['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "8b5e098f-10b7-4bba-a735-f8f7e4e676ce",
    "_uuid": "e3f03f358f98d64c9b6fa429c77f68f6a4929586",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "size_tfidf = 50000\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(train[num_features])\n",
    "X_test_num = scaler.transform(test[num_features])\n",
    "X_train_cat = np.array(train[cat_features_hash], dtype=np.int)\n",
    "X_test_cat = np.array(test[cat_features_hash], dtype=np.int)\n",
    "tfidf = TfidfVectorizer(max_features=size_tfidf)\n",
    "X_train_tfidf = tfidf.fit_transform(train[\"text\"].tolist())\n",
    "X_test_tfidf = tfidf.transform(test[\"text\"].tolist())\n",
    "\n",
    "\n",
    "X_train_target = train.project_is_approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n",
      "2743\n",
      "  (0, 25954)\t0.0188991502816\n",
      "  (0, 39599)\t0.0195371268212\n",
      "  (0, 3186)\t0.0271134665809\n",
      "  (0, 39603)\t0.0328056531363\n",
      "  (0, 38681)\t0.111761119093\n",
      "  (0, 2880)\t0.07324442159\n",
      "  (0, 35869)\t0.609090971277\n",
      "  (0, 25053)\t0.0191318807012\n",
      "  (0, 18155)\t0.0399575498589\n",
      "  (0, 27864)\t0.0627588696782\n",
      "  (0, 43309)\t0.115057927743\n",
      "  (0, 15566)\t0.0299257786198\n",
      "  (0, 29326)\t0.0615967834445\n",
      "  (0, 15563)\t0.0553400958178\n",
      "  (0, 44932)\t0.118018399895\n",
      "  (0, 48526)\t0.0279647466928\n",
      "  (0, 49451)\t0.0642398183838\n",
      "  (0, 24589)\t0.0235175629883\n",
      "  (0, 45465)\t0.2405875587\n",
      "  (0, 18145)\t0.0502638373649\n",
      "  (0, 32770)\t0.0127979305786\n",
      "  (0, 22387)\t0.0233205905916\n",
      "  (0, 2828)\t0.0168226416951\n",
      "  (0, 21168)\t0.0422760395359\n",
      "  (0, 18620)\t0.0558982430866\n",
      "  :\t:\n",
      "  (0, 2633)\t0.0192570082683\n",
      "  (0, 2566)\t0.0223811174551\n",
      "  (0, 47415)\t0.0270872447872\n",
      "  (0, 12229)\t0.0240868778009\n",
      "  (0, 24417)\t0.034319988969\n",
      "  (0, 7650)\t0.0387328465309\n",
      "  (0, 12075)\t0.0546054701929\n",
      "  (0, 39560)\t0.0121037745353\n",
      "  (0, 48858)\t0.0210372189016\n",
      "  (0, 14499)\t0.0403423761202\n",
      "  (0, 47307)\t0.0230662270392\n",
      "  (0, 44294)\t0.0412528623678\n",
      "  (0, 11910)\t0.0381185128642\n",
      "  (0, 17512)\t0.0263299460689\n",
      "  (0, 22987)\t0.026482450312\n",
      "  (0, 22477)\t0.035385681118\n",
      "  (0, 39720)\t0.0523807033179\n",
      "  (0, 49147)\t0.0324418426528\n",
      "  (0, 19486)\t0.0249857841966\n",
      "  (0, 7645)\t0.0375199280199\n",
      "  (0, 25700)\t0.0167107294408\n",
      "  (0, 32744)\t0.0225124868481\n",
      "  (0, 45070)\t0.0285333143231\n",
      "  (0, 17169)\t0.0432757525356\n",
      "  (0, 19715)\t0.0151030424934\n",
      "(182080, 50000)\n",
      "182080\n"
     ]
    }
   ],
   "source": [
    "testing1 = train[\"text\"].tolist()\n",
    "#print(train[\"text\"].head())\n",
    "#print(testing1[0])\n",
    "print(len(testing1[0]))\n",
    "print(len(testing1[1]))\n",
    "# Below is an array\n",
    "print(X_train_tfidf[0])\n",
    "# Finding the shape of the array\n",
    "print(X_train_tfidf.shape)\n",
    "print(len(X_train_target))\n",
    "# VERIFIED TILL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "ec5c6764-5f3b-4499-a6b7-44e87d2c573d",
    "_uuid": "2d915fdd061d9a07c73fcde4794036e63a5236fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Flatten, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "def get_model():\n",
    "    input_cat = Input((len(cat_features_hash), ))\n",
    "    input_num = Input((len(num_features), ))\n",
    "    input_tfidf = Input((size_tfidf, ), sparse=True)\n",
    "    \n",
    "    x_cat = Embedding(max_size, 10)(input_cat)\n",
    "    x_cat = Flatten()(x_cat)\n",
    "    x_cat = Dropout(0.5)(x_cat)\n",
    "    x_tfidf = Dense(100, activation=\"relu\")(input_tfidf)\n",
    "    x_tfidf = Dropout(0.5)(x_tfidf)\n",
    "    \n",
    "    x_cat = Dense(100, activation=\"relu\")(x_cat)\n",
    "    x_num = Dense(100, activation=\"relu\")(input_num)\n",
    "    x_num = Dropout(0.5)(x_num)\n",
    "    x = concatenate([x_cat, x_num, x_tfidf])\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=[input_cat, input_num, input_tfidf], outputs=predictions)\n",
    "    model.compile(optimizer=optimizers.Adam(0.001, decay=1e-6),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 7)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 7, 10)         150000      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 70)            0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 4)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 50000)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 70)            0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           500         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           5000100     input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           7100        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 100)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 300)           0           dense_2[0][0]                    \n",
      "                                                                   dropout_3[0][0]                  \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 50)            15050       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 50)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             51          dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5,172,801\n",
      "Trainable params: 5,172,801\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_cell_guid": "785f12b8-0bbb-43b5-a709-dabd163017ce",
    "_uuid": "58ac03b1c6ae802a41e3d33f9e61f3dce3e20b3a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 1 : Provided as a benchmark code \n",
    "#model = get_model()\n",
    "#model.fit([X_train_cat, X_train_num, X_train_tfidf], X_train_target, validation_split=0.1, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 163872 samples, validate on 18208 samples\n",
      "Epoch 1/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.3370 - acc: 0.8656Epoch 00000: val_loss improved from inf to 0.36198, saving model to C:/Users/skumarravindran/Documents/keras_save_model/kaggle_donors/weights.hdf5\n",
      "163872/163872 [==============================] - 39s - loss: 0.3369 - acc: 0.8656 - val_loss: 0.3620 - val_acc: 0.8570\n",
      "Epoch 2/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.8744Epoch 00001: val_loss did not improve\n",
      "163872/163872 [==============================] - 39s - loss: 0.3196 - acc: 0.8744 - val_loss: 0.3712 - val_acc: 0.8540\n",
      "Epoch 3/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8866Epoch 00002: val_loss did not improve\n",
      "163872/163872 [==============================] - 39s - loss: 0.2980 - acc: 0.8866 - val_loss: 0.3859 - val_acc: 0.8536\n",
      "Epoch 4/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.8969Epoch 00003: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.2731 - acc: 0.8969 - val_loss: 0.4117 - val_acc: 0.8388\n",
      "Epoch 5/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.9099Epoch 00004: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.2450 - acc: 0.9099 - val_loss: 0.4362 - val_acc: 0.8416\n",
      "Epoch 6/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9188Epoch 00005: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.2212 - acc: 0.9189 - val_loss: 0.4634 - val_acc: 0.8406\n",
      "Epoch 7/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9277Epoch 00006: val_loss did not improve\n",
      "163872/163872 [==============================] - 39s - loss: 0.1971 - acc: 0.9277 - val_loss: 0.5021 - val_acc: 0.8361\n",
      "Epoch 8/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.1771 - acc: 0.9359Epoch 00007: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.1771 - acc: 0.9359 - val_loss: 0.5433 - val_acc: 0.8384\n",
      "Epoch 9/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9416Epoch 00008: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.1600 - acc: 0.9416 - val_loss: 0.5920 - val_acc: 0.8273\n",
      "Epoch 10/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9475Epoch 00009: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.1451 - acc: 0.9475 - val_loss: 0.6242 - val_acc: 0.8311\n",
      "Epoch 11/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9522- - ETA: 1s - loEpoch 00010: val_loss did not improve\n",
      "163872/163872 [==============================] - 40s - loss: 0.1327 - acc: 0.9522 - val_loss: 0.6610 - val_acc: 0.8330\n",
      "Epoch 12/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9571Epoch 00011: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.1205 - acc: 0.9571 - val_loss: 0.7254 - val_acc: 0.8375\n",
      "Epoch 13/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9600Epoch 00012: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.1121 - acc: 0.9600 - val_loss: 0.7170 - val_acc: 0.8346\n",
      "Epoch 14/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9633Epoch 00013: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.1033 - acc: 0.9633 - val_loss: 0.7810 - val_acc: 0.8342\n",
      "Epoch 15/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9656Epoch 00014: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0961 - acc: 0.9656 - val_loss: 0.7920 - val_acc: 0.8325\n",
      "Epoch 16/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9679Epoch 00015: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0912 - acc: 0.9679 - val_loss: 0.8037 - val_acc: 0.8332\n",
      "Epoch 17/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9693Epoch 00016: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0860 - acc: 0.9693 - val_loss: 0.8298 - val_acc: 0.8327\n",
      "Epoch 18/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9717Epoch 00017: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0804 - acc: 0.9717 - val_loss: 0.8879 - val_acc: 0.8340\n",
      "Epoch 19/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9724Epoch 00018: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0779 - acc: 0.9724 - val_loss: 0.9086 - val_acc: 0.8346\n",
      "Epoch 20/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9738- Epoch 00019: val_loss did not improve\n",
      "163872/163872 [==============================] - 41s - loss: 0.0735 - acc: 0.9738 - val_loss: 0.8992 - val_acc: 0.8307\n",
      "Epoch 21/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9755Epoch 00020: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0688 - acc: 0.9755 - val_loss: 0.9486 - val_acc: 0.8328\n",
      "Epoch 22/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9767Epoch 00021: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0663 - acc: 0.9767 - val_loss: 0.9829 - val_acc: 0.8347\n",
      "Epoch 23/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9769Epoch 00022: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0653 - acc: 0.9769 - val_loss: 0.9866 - val_acc: 0.8336\n",
      "Epoch 24/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9771Epoch 00023: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0638 - acc: 0.9771 - val_loss: 0.9794 - val_acc: 0.8320\n",
      "Epoch 25/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9787Epoch 00024: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0603 - acc: 0.9787 - val_loss: 0.9849 - val_acc: 0.8298\n",
      "Epoch 26/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9793Epoch 00025: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0577 - acc: 0.9793 - val_loss: 1.0016 - val_acc: 0.8275\n",
      "Epoch 27/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9800Epoch 00026: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0565 - acc: 0.9800 - val_loss: 1.0103 - val_acc: 0.8305\n",
      "Epoch 28/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9802Epoch 00027: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0554 - acc: 0.9802 - val_loss: 1.0407 - val_acc: 0.8285\n",
      "Epoch 29/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9810Epoch 00028: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0535 - acc: 0.9810 - val_loss: 1.0544 - val_acc: 0.8331\n",
      "Epoch 30/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9812Epoch 00029: val_loss did not improve\n",
      "163872/163872 [==============================] - 36s - loss: 0.0532 - acc: 0.9812 - val_loss: 1.0669 - val_acc: 0.8302\n",
      "Epoch 31/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9815Epoch 00030: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0517 - acc: 0.9815 - val_loss: 1.0919 - val_acc: 0.8325\n",
      "Epoch 32/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9821Epoch 00031: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0502 - acc: 0.9822 - val_loss: 1.1210 - val_acc: 0.8345\n",
      "Epoch 33/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9823Epoch 00032: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0499 - acc: 0.9823 - val_loss: 1.1071 - val_acc: 0.8285\n",
      "Epoch 34/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9825Epoch 00033: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0491 - acc: 0.9825 - val_loss: 1.1427 - val_acc: 0.8345\n",
      "Epoch 35/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9832Epoch 00034: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0473 - acc: 0.9831 - val_loss: 1.1436 - val_acc: 0.8319\n",
      "Epoch 36/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9831Epoch 00035: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0469 - acc: 0.9831 - val_loss: 1.1776 - val_acc: 0.8330\n",
      "Epoch 37/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9834Epoch 00036: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0458 - acc: 0.9834 - val_loss: 1.1768 - val_acc: 0.8340\n",
      "Epoch 38/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9841Epoch 00037: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0446 - acc: 0.9841 - val_loss: 1.1614 - val_acc: 0.8288\n",
      "Epoch 39/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9838Epoch 00038: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0453 - acc: 0.9837 - val_loss: 1.2155 - val_acc: 0.8341\n",
      "Epoch 40/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9848Epoch 00039: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0430 - acc: 0.9848 - val_loss: 1.2122 - val_acc: 0.8334\n",
      "Epoch 41/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9849Epoch 00040: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0427 - acc: 0.9849 - val_loss: 1.2187 - val_acc: 0.8318\n",
      "Epoch 42/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9844Epoch 00041: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0433 - acc: 0.9844 - val_loss: 1.2293 - val_acc: 0.8351\n",
      "Epoch 43/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9848Epoch 00042: val_loss did not improve\n",
      "163872/163872 [==============================] - 37s - loss: 0.0415 - acc: 0.9848 - val_loss: 1.2470 - val_acc: 0.8350\n",
      "Epoch 44/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9856Epoch 00043: val_loss did not improve\n",
      "163872/163872 [==============================] - 40s - loss: 0.0401 - acc: 0.9856 - val_loss: 1.2199 - val_acc: 0.8290\n",
      "Epoch 45/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9853Epoch 00044: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0418 - acc: 0.9853 - val_loss: 1.2454 - val_acc: 0.8341\n",
      "Epoch 46/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9848- ETA: 1s - loss: Epoch 00045: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0417 - acc: 0.9848 - val_loss: 1.2540 - val_acc: 0.8340\n",
      "Epoch 47/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9853Epoch 00046: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0406 - acc: 0.9853 - val_loss: 1.2317 - val_acc: 0.8307\n",
      "Epoch 48/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9855Epoch 00047: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0413 - acc: 0.9855 - val_loss: 1.2468 - val_acc: 0.8325\n",
      "Epoch 49/50\n",
      "163712/163872 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9858Epoch 00048: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0396 - acc: 0.9858 - val_loss: 1.2463 - val_acc: 0.8328\n",
      "Epoch 50/50\n",
      "163840/163872 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9859Epoch 00049: val_loss did not improve\n",
      "163872/163872 [==============================] - 38s - loss: 0.0385 - acc: 0.9859 - val_loss: 1.2798 - val_acc: 0.8327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c08c6c19b0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2 : Adding feature to save the best model so that it can be used for prediction.\n",
    "batch_size = 128   # \n",
    "epochs = 50 #\n",
    "checkpointer = ModelCheckpoint(filepath=\"C:/Users/skumarravindran/Documents/keras_save_model/kaggle_donors/weights.hdf5\", verbose=1, save_best_only=True)\n",
    "model.fit([X_train_cat, X_train_num, X_train_tfidf], X_train_target, validation_split=0.1,\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To load weights in case of option 2 only\n",
    "model.load_weights('C:/Users/skumarravindran/Documents/keras_save_model/kaggle_donors/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "6e935a5c-c498-477a-8aff-9584b56502bb",
    "_uuid": "a65d34c4e98e7085cab5a7ac2405240dced277a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict([X_test_cat, X_test_num, X_test_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "91f918eb-1e71-4657-a70e-cbb4bbc93118",
    "_uuid": "10711d3d0d0e3e0ab2cd6797b5402f107d3400d8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"project_is_approved\"] = pred_test\n",
    "test[['id', 'project_is_approved']].to_csv(\"baseline_submission_200317.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
