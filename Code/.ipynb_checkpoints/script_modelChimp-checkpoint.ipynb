{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resources.csv', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../Input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Model Chimp package\n",
    "import zlib\n",
    "from modelchimp import ModelChimp\n",
    "mc = ModelChimp(\"rsharankumar@gmail.com\",\"mcsharan\", \"d0294c90-90f5-4a4b-bc19-efd9443a1218\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "resources = pd.read_csv(\"../input/resources.csv\")\n",
    "train = train.sort_values(by=\"project_submitted_datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved']\n",
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects']\n"
     ]
    }
   ],
   "source": [
    "# print sample rows from train and test dataset\n",
    "#print(train.head())\n",
    "#print(test.head())\n",
    "#printing column names of train and test datasets\n",
    "print(train.columns.values)\n",
    "print(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f592a49e-f0d0-4e26-ae59-5bfe7434248b",
    "_uuid": "72a58c08a2d4498e4628af5e344dafb4bee99f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'description' 'quantity' 'price']\n",
      "        id                                        description  quantity  \\\n",
      "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
      "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
      "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
      "3  p069063  Dixon Ticonderoga Wood-Cased #2 HB Pencils, Bo...         2   \n",
      "4  p069063  EDUCATIONAL INSIGHTS FLUORESCENT LIGHT FILTERS...         3   \n",
      "\n",
      "    price  \n",
      "0  149.00  \n",
      "1   14.95  \n",
      "2    8.45  \n",
      "3   13.59  \n",
      "4   24.95  \n"
     ]
    }
   ],
   "source": [
    "# Checking the resources datasets\n",
    "print(resources.columns.values)\n",
    "print(resources.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ids in Resources: 260115\n",
      "Count ids in Resources: 1541272\n",
      "Unique ids in train: 182080\n",
      "Count ids in train: 182080\n",
      "Unique ids in test: 78035\n",
      "Count ids in test: 78035\n",
      "Unique ids in test+train: 260115\n"
     ]
    }
   ],
   "source": [
    "# Performing basic count checks\n",
    "print(\"Unique ids in Resources:\", resources['id'].nunique())\n",
    "print(\"Count ids in Resources:\", resources['id'].count())\n",
    "print(\"Unique ids in train:\", train['id'].nunique())\n",
    "print(\"Count ids in train:\", train['id'].count())\n",
    "print(\"Unique ids in test:\", test['id'].nunique())\n",
    "print(\"Count ids in test:\", test['id'].count())\n",
    "print(\"Unique ids in test+train:\", train['id'].nunique() + test['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "1b8a0111-65da-49d0-8aa1-14db0c4c8600",
    "_uuid": "fd0e3b2ceaffa53a0704835e80b5e4af80150e97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To check the overlap between the teachers_id between the train and the test\n",
    "teachers_train = list(set(train.teacher_id.values))\n",
    "teachers_test = list(set(test.teacher_id.values))\n",
    "inter = set(teachers_train).intersection(teachers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "788ca21e-68b1-4fa3-81be-bacfb409719c",
    "_uuid": "5c66ea49dc1dbe24415c5b7f0fafa4c493eec321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number teachers train : 104414, Number teachers test : 55508, Overlap : 27789 \n"
     ]
    }
   ],
   "source": [
    "print(\"Number teachers train : %s, Number teachers test : %s, Overlap : %s \"%(len(teachers_train), len(teachers_test), len(inter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "124ee5e2-d7c0-46ce-bc54-5c3dc6a74b3f",
    "_uuid": "f808ed8bd3e0860f30b0c3ea50061bae31c22c82",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_cols = ['project_subject_categories', 'project_subject_subcategories',\n",
    "       'project_title', 'project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4', 'project_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "62aaa5f9-6313-44cb-9401-03b4f7d2a103",
    "_uuid": "69d9a051b7cbf0e542480ac6c432f2a575ec5b77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/mmi333/beat-the-benchmark-with-one-feature\n",
    "resources['total_price'] = resources.quantity * resources.price\n",
    "\n",
    "mean_total_price = pd.DataFrame(resources.groupby('id').total_price.mean()) \n",
    "sum_total_price = pd.DataFrame(resources.groupby('id').total_price.sum()) \n",
    "count_total_price = pd.DataFrame(resources.groupby('id').total_price.count())\n",
    "max_total_price = pd.DataFrame(resources.groupby('id').total_price.max()) # Newly added\n",
    "min_total_price = pd.DataFrame(resources.groupby('id').total_price.min()) # Newly added\n",
    "std_total_price = pd.DataFrame(resources.groupby('id').total_price.std()) # Newly added\n",
    "mean_total_price['id'] = mean_total_price.index\n",
    "sum_total_price['id'] = sum_total_price.index\n",
    "count_total_price['id'] = count_total_price.index\n",
    "max_total_price['id'] = max_total_price.index\n",
    "min_total_price['id'] = min_total_price.index\n",
    "std_total_price['id'] = std_total_price.index\n",
    "\n",
    "def create_features(df):\n",
    "    \n",
    "    df = pd.merge(df, mean_total_price, on='id')\n",
    "    df = pd.merge(df, sum_total_price, on='id')\n",
    "    df = pd.merge(df, count_total_price, on='id')\n",
    "    df = pd.merge(df, max_total_price, on='id')\n",
    "    df = pd.merge(df, min_total_price, on='id')\n",
    "    df = pd.merge(df, std_total_price, on='id')\n",
    "    df['year'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[0])\n",
    "    df['month'] = df.project_submitted_datetime.apply(lambda x: x.split(\"-\")[1])\n",
    "    for col in char_cols:\n",
    "        df[col] = df[col].fillna(\"NA\")\n",
    "    df['text'] = df.apply(lambda x: \" \".join(x[col] for col in char_cols), axis=1)\n",
    "    return df\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns = ['id','teacher_id','teacher_prefix','school_state','project_submitted_datetime','project_grade_category','project_subject_categories','project_subject_subcategories','project_title','project_essay_1','project_essay_2','project_essay_3','project_essay_4','project_resource_summary','teacher_number_of_previously_posted_projects','project_is_approved','mean_total_price','sum_total_price','count_total_price','max_total_price','min_total_price','std_total_price','year','month','text']\n",
    "test.columns = ['id','teacher_id','teacher_prefix','school_state','project_submitted_datetime','project_grade_category','project_subject_categories','project_subject_subcategories','project_title','project_essay_1','project_essay_2','project_essay_3','project_essay_4','project_resource_summary','teacher_number_of_previously_posted_projects','mean_total_price','sum_total_price','count_total_price','max_total_price','min_total_price','std_total_price','year','month','text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'mean_total_price' 'sum_total_price' 'count_total_price' 'max_total_price'\n",
      " 'min_total_price' 'std_total_price' 'year' 'month' 'text']\n",
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'mean_total_price'\n",
      " 'sum_total_price' 'count_total_price' 'max_total_price' 'min_total_price'\n",
      " 'std_total_price' 'year' 'month' 'text']\n"
     ]
    }
   ],
   "source": [
    "print(train.columns.values)\n",
    "print(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "### CODE TO ADD NEW FEATURES THAT HAS GOOD CORRELATION WITH THE SELECTION RATE#\n",
    "###############################################################################\n",
    "# Columns that has the project essay text\n",
    "##essay_cols = ['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']\n",
    "# creating a separate column to hold the project essay\n",
    "##train['essay_text'] = train.apply(lambda x: \" \".join(x[col] for col in essay_cols), axis=1)\n",
    "##test['essay_text'] = test.apply(lambda x: \" \".join(x[col] for col in essay_cols), axis=1)\n",
    "\n",
    "# Preprocess data\n",
    "train['project_essay'] = train.apply(lambda row: ' '.join([\n",
    "    str(row['teacher_prefix']), \n",
    "    str(row['school_state']), \n",
    "    str(row['project_grade_category']), \n",
    "    str(row['project_subject_categories']), \n",
    "    str(row['project_subject_subcategories']), \n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "test['project_essay'] = test.apply(lambda row: ' '.join([\n",
    "    str(row['teacher_prefix']), \n",
    "    str(row['school_state']), \n",
    "    str(row['project_grade_category']), \n",
    "    str(row['project_subject_categories']), \n",
    "    str(row['project_subject_subcategories']), \n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "def get_polarity(text):\n",
    "    textblob = TextBlob(str(str.encode(text), 'utf-8'))\n",
    "    #textblob = TextBlob(str(b'text', 'utf-8'))\n",
    "    pol = textblob.sentiment.polarity\n",
    "    return round(pol,3)\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    textblob = TextBlob(str(str.encode(text), 'utf-8'))\n",
    "    #textblob = TextBlob(str(b'text', 'utf-8'))\n",
    "    subj = textblob.sentiment.subjectivity\n",
    "    return round(subj,3)\n",
    "\n",
    "train['polarity'] = train['project_essay'].apply(get_polarity)\n",
    "train['subjectivity'] = train['project_essay'].apply(get_subjectivity)\n",
    "test['polarity'] = test['project_essay'].apply(get_polarity)\n",
    "test['subjectivity'] = test['project_essay'].apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Drop unwanted features\n",
    "\n",
    "train = train.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4',\n",
    "    'std_total_price'], axis=1)\n",
    "test = test.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4',\n",
    "    'std_total_price'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p146022  f91a89d2b72a0f5ee14cd98bd8741fc2            Ms.           CA   \n",
      "1  p244738  64ef8a335f7206366c52c39f5bfd09b7            Ms.           TX   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-04-27 00:03:38             Grades 6-8   \n",
      "1        2016-04-27 00:04:09          Grades PreK-2   \n",
      "\n",
      "            project_subject_categories   project_subject_subcategories  \\\n",
      "0                       Math & Science                Applied Sciences   \n",
      "1  Literacy & Language, Math & Science  Foreign Languages, Mathematics   \n",
      "\n",
      "                            project_title  \\\n",
      "0                Robotics and Programming   \n",
      "1  Help Us Finish Our 1st Year In School!   \n",
      "\n",
      "                            project_resource_summary  \\\n",
      "0  My students need four Sparki robots to help st...   \n",
      "1  My students need Linking Letter Monkeys and Sp...   \n",
      "\n",
      "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
      "0                                            30                    1   \n",
      "1                                             1                    1   \n",
      "\n",
      "   mean_total_price  sum_total_price  count_total_price  max_total_price  \\\n",
      "0           596.000           596.00                  1           596.00   \n",
      "1            28.786           287.86                 10            49.99   \n",
      "\n",
      "   min_total_price  year month  \\\n",
      "0           596.00  2016    04   \n",
      "1             9.99  2016    04   \n",
      "\n",
      "                                                text  \n",
      "0  Math & Science Applied Sciences Robotics and P...  \n",
      "1  Literacy & Language, Math & Science Foreign La...  \n"
     ]
    }
   ],
   "source": [
    "#TO CHECK THE POLARITY AND SUBJECTIVITY SCORES FOR ATLEAST 2 ROWS\n",
    "print(train.head(2))\n",
    "\n",
    "#TESTING DATA TYPES\n",
    "#my_str = \"hello world\"\n",
    "#print(type(my_str))\n",
    "#my_str_as_bytes = str.encode(my_str)\n",
    "#print(type(my_str_as_bytes)) # ensure it is byte representation\n",
    "#my_decoded_str = my_str_as_bytes.decode()\n",
    "#print(type(my_decoded_str)) # ensure it is string representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########TESTING##################################\n",
    "\n",
    "# Testing the test columns merging logic\n",
    "# Creating a sample data frame\n",
    "#df_test = pd.DataFrame([['1A', '2B', '3C'], ['4A', '5B', '6C'], ['7A', '8B', '9C']])\n",
    "#df_test.columns = ['One', 'Two', 'Three']\n",
    "#print(df_test)\n",
    "# Specifying the columns to be merged\n",
    "#char1_cols = ['One', 'Two', 'Three']\n",
    "# Merging the columns\n",
    "#df_test['text'] = df_test.apply(lambda x: \" \".join(x[col] for col in char1_cols), axis=1)\n",
    "#print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########TESTING##################################\n",
    "\n",
    "# Checking the numeric values: Looking consistent\n",
    "#print(mean_total_price.loc['p146022',:])\n",
    "#print(sum_total_price.loc['p146022',:])\n",
    "#print(count_total_price.loc['p146022',:])\n",
    "#print(train.head())\n",
    "\n",
    "# Checking the text columns\n",
    "#print(train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "cd94beed-d105-459e-920a-7e2bd041520b",
    "_uuid": "e3d6230e3bf65049b2d58272d53d01323e37bbf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved'\n",
      " 'mean_total_price' 'sum_total_price' 'count_total_price' 'max_total_price'\n",
      " 'min_total_price' 'year' 'month' 'text' 'project_essay' 'polarity'\n",
      " 'subjectivity']\n",
      "['id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'mean_total_price'\n",
      " 'sum_total_price' 'count_total_price' 'max_total_price' 'min_total_price'\n",
      " 'year' 'month' 'text' 'project_essay' 'polarity' 'subjectivity']\n"
     ]
    }
   ],
   "source": [
    "# With Newly added columns\n",
    "print(train.columns.values)\n",
    "print(test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "7742c5d2-5d8e-4965-9a1c-a2c2a0164bee",
    "_uuid": "0f84509b4bfbe8555e3f88df35f04ee57c20c435",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = [\"teacher_prefix\", \"school_state\", \"year\", \"month\", \"project_grade_category\", \"project_subject_categories\", \"project_subject_subcategories\"]\n",
    "#\"teacher_id\", \n",
    "num_features = [\"teacher_number_of_previously_posted_projects\", \"mean_total_price\", \"sum_total_price\", \"count_total_price\", \"max_total_price\", \"min_total_price\"]\n",
    "cat_features_hash = [col+\"_hash\" for col in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "6f9594b5-155e-47a5-b6f5-24d3ac49ffee",
    "_uuid": "a2c15bc8a55fcb1c571cfbe6b7062fa2294e581f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_size=15000#0\n",
    "def feature_hash(df, max_size=max_size):\n",
    "    for col in cat_features:\n",
    "        df[col+\"_hash\"] = df[col].apply(lambda x: hash(x)%max_size)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "ccd45300-40ac-4894-b14a-cd5b026aacac",
    "_uuid": "4dc775237b3a4ca40458919bbe9488b0c295fb10",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hashing converts the categorical columns to numerical values\n",
    "train = feature_hash(train)\n",
    "test = feature_hash(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p146022  f91a89d2b72a0f5ee14cd98bd8741fc2            Ms.           CA   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-04-27 00:03:38             Grades 6-8   \n",
      "\n",
      "  project_subject_categories project_subject_subcategories  \\\n",
      "0             Math & Science              Applied Sciences   \n",
      "\n",
      "              project_title  \\\n",
      "0  Robotics and Programming   \n",
      "\n",
      "                            project_resource_summary  \\\n",
      "0  My students need four Sparki robots to help st...   \n",
      "\n",
      "                 ...                  year  month  \\\n",
      "0                ...                  2016     04   \n",
      "\n",
      "                                                text  teacher_prefix_hash  \\\n",
      "0  Math & Science Applied Sciences Robotics and P...                 1511   \n",
      "\n",
      "   school_state_hash  year_hash  month_hash project_grade_category_hash  \\\n",
      "0               6790        208        5188                        6953   \n",
      "\n",
      "  project_subject_categories_hash project_subject_subcategories_hash  \n",
      "0                            2062                               2294  \n",
      "\n",
      "[1 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "dddf070f-e7fb-40e5-aba2-71c88c95f79e",
    "_uuid": "012e5a280f975a7a85eaa5911f8c158447138a4b"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'std_total_price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2392\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'std_total_price'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-688e1ba086f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#'sum_total_price' 'count_total_price' 'max_total_price' 'min_total_price'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 'std_total_price'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_total_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2393\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2395\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'std_total_price'"
     ]
    }
   ],
   "source": [
    "# Printing sample text column\n",
    "#'sum_total_price' 'count_total_price' 'max_total_price' 'min_total_price'\n",
    "# 'std_total_price'\n",
    "print(train['std_total_price'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "8b5e098f-10b7-4bba-a735-f8f7e4e676ce",
    "_uuid": "e3f03f358f98d64c9b6fa429c77f68f6a4929586",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "size_tfidf = 50000\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(train[num_features])\n",
    "X_test_num = scaler.transform(test[num_features])\n",
    "X_train_cat = np.array(train[cat_features_hash], dtype=np.int)\n",
    "X_test_cat = np.array(test[cat_features_hash], dtype=np.int)\n",
    "tfidf = TfidfVectorizer(max_features=size_tfidf)\n",
    "X_train_tfidf = tfidf.fit_transform(train[\"text\"].tolist())\n",
    "X_test_tfidf = tfidf.transform(test[\"text\"].tolist())\n",
    "\n",
    "\n",
    "X_train_target = train.project_is_approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(X_train_num[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n",
      "2743\n",
      "  (0, 25954)\t0.0188991502816\n",
      "  (0, 39599)\t0.0195371268212\n",
      "  (0, 3186)\t0.0271134665809\n",
      "  (0, 39603)\t0.0328056531363\n",
      "  (0, 38681)\t0.111761119093\n",
      "  (0, 2880)\t0.07324442159\n",
      "  (0, 35869)\t0.609090971277\n",
      "  (0, 25053)\t0.0191318807012\n",
      "  (0, 18155)\t0.0399575498589\n",
      "  (0, 27864)\t0.0627588696782\n",
      "  (0, 43309)\t0.115057927743\n",
      "  (0, 15566)\t0.0299257786198\n",
      "  (0, 29326)\t0.0615967834445\n",
      "  (0, 15563)\t0.0553400958178\n",
      "  (0, 44932)\t0.118018399895\n",
      "  (0, 48526)\t0.0279647466928\n",
      "  (0, 49451)\t0.0642398183838\n",
      "  (0, 24589)\t0.0235175629883\n",
      "  (0, 45465)\t0.2405875587\n",
      "  (0, 18145)\t0.0502638373649\n",
      "  (0, 32770)\t0.0127979305786\n",
      "  (0, 22387)\t0.0233205905916\n",
      "  (0, 2828)\t0.0168226416951\n",
      "  (0, 21168)\t0.0422760395359\n",
      "  (0, 18620)\t0.0558982430866\n",
      "  :\t:\n",
      "  (0, 2633)\t0.0192570082683\n",
      "  (0, 2566)\t0.0223811174551\n",
      "  (0, 47415)\t0.0270872447872\n",
      "  (0, 12229)\t0.0240868778009\n",
      "  (0, 24417)\t0.034319988969\n",
      "  (0, 7650)\t0.0387328465309\n",
      "  (0, 12075)\t0.0546054701929\n",
      "  (0, 39560)\t0.0121037745353\n",
      "  (0, 48858)\t0.0210372189016\n",
      "  (0, 14499)\t0.0403423761202\n",
      "  (0, 47307)\t0.0230662270392\n",
      "  (0, 44294)\t0.0412528623678\n",
      "  (0, 11910)\t0.0381185128642\n",
      "  (0, 17512)\t0.0263299460689\n",
      "  (0, 22987)\t0.026482450312\n",
      "  (0, 22477)\t0.035385681118\n",
      "  (0, 39720)\t0.0523807033179\n",
      "  (0, 49147)\t0.0324418426528\n",
      "  (0, 19486)\t0.0249857841966\n",
      "  (0, 7645)\t0.0375199280199\n",
      "  (0, 25700)\t0.0167107294408\n",
      "  (0, 32744)\t0.0225124868481\n",
      "  (0, 45070)\t0.0285333143231\n",
      "  (0, 17169)\t0.0432757525356\n",
      "  (0, 19715)\t0.0151030424934\n",
      "(182080, 50000)\n",
      "182080\n"
     ]
    }
   ],
   "source": [
    "testing1 = train[\"text\"].tolist()\n",
    "#print(train[\"text\"].head())\n",
    "#print(testing1[0])\n",
    "print(len(testing1[0]))\n",
    "print(len(testing1[1]))\n",
    "# Below is an array\n",
    "print(X_train_tfidf[0])\n",
    "# Finding the shape of the array\n",
    "print(X_train_tfidf.shape)\n",
    "print(len(X_train_target))\n",
    "# VERIFIED TILL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "ec5c6764-5f3b-4499-a6b7-44e87d2c573d",
    "_uuid": "2d915fdd061d9a07c73fcde4794036e63a5236fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Flatten, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import optimizers\n",
    "\n",
    "def get_model():\n",
    "    input_cat = Input((len(cat_features_hash), ))\n",
    "    input_num = Input((len(num_features), ))\n",
    "    input_tfidf = Input((size_tfidf, ), sparse=True)\n",
    "    \n",
    "    x_cat = Embedding(max_size, 10)(input_cat)\n",
    "    x_cat = Flatten()(x_cat)\n",
    "    x_cat = Dropout(0.5)(x_cat)\n",
    "    x_tfidf = Dense(100, activation=\"relu\")(input_tfidf)\n",
    "    x_tfidf = Dropout(0.5)(x_tfidf)\n",
    "    \n",
    "    x_cat = Dense(100, activation=\"relu\")(x_cat)\n",
    "    x_num = Dense(100, activation=\"relu\")(input_num)\n",
    "    x_num = Dropout(0.5)(x_num)\n",
    "    x = concatenate([x_cat, x_num, x_tfidf])\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=[input_cat, input_num, input_tfidf], outputs=predictions)\n",
    "    #model.compile(optimizer=optimizers.Adam(0.001, decay=1e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 7)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 7, 10)         150000      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 70)            0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 50000)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 70)            0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           700         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           5000100     input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           7100        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 100)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 300)           0           dense_2[0][0]                    \n",
      "                                                                   dropout_3[0][0]                  \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 50)            15050       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 50)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             51          dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5,173,001\n",
      "Trainable params: 5,173,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "#len(cat_features_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "785f12b8-0bbb-43b5-a709-dabd163017ce",
    "_uuid": "58ac03b1c6ae802a41e3d33f9e61f3dce3e20b3a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 1 : Provided as a benchmark code \n",
    "#model = get_model()\n",
    "#model.fit([X_train_cat, X_train_num, X_train_tfidf], X_train_target, validation_split=0.1, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(model)\n",
    "from keras.engine.training import Model\n",
    "from keras.models import Sequential\n",
    "Seq =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 145664 samples, validate on 36416 samples\n",
      "Epoch 1/1\n",
      "144896/145664 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.8462Epoch 00000: val_loss improved from inf to 0.10790, saving model to C:/Users/skumarravindran/Documents/keras_save_model/kaggle_donors/weights.hdf5\n",
      "145664/145664 [==============================] - 14s - loss: 0.1216 - acc: 0.8461 - val_loss: 0.1079 - val_acc: 0.8596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24087058b70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2 : Adding feature to save the best model so that it can be used for prediction.\n",
    "batch_size = 512   #128 \n",
    "epochs = 1 #\n",
    "\n",
    "checkpointer = [EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=7, mode='auto', verbose=1), ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5, min_lr=0), CSVLogger('C:/Users/skumarravindran/Desktop/Kaggle/DonorsChoose.org Application Screening/Code/training_log.csv'), ModelCheckpoint(filepath=\"C:/Users/skumarravindran/Documents/keras_save_model/kaggle_donors/weights.hdf5\", verbose=1, save_best_only=True)]\n",
    "\n",
    "model.fit([X_train_cat, X_train_num, X_train_tfidf], X_train_target, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To load weights in case of option 2 only\n",
    "model.load_weights('C:/Users/skumarravindran/Documents/keras_save_model/kaggle_donors/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "6e935a5c-c498-477a-8aff-9584b56502bb",
    "_uuid": "a65d34c4e98e7085cab5a7ac2405240dced277a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict([X_test_cat, X_test_num, X_test_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "91f918eb-1e71-4657-a70e-cbb4bbc93118",
    "_uuid": "10711d3d0d0e3e0ab2cd6797b5402f107d3400d8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"project_is_approved\"] = pred_test\n",
    "test[['id', 'project_is_approved']].to_csv(\"mc_testing_250317.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_testing = pd.read_csv(\"baseline_submission_20180404v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modelchimp.keras import Sequential\n",
    "from modelchimp import metrics, ModelChimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from modelchimp import library_base_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'sklearn.base.BaseEstimator'>, <class 'keras.models.Sequential'>, <class 'keras.layers.embeddings.Embedding'>]\n"
     ]
    }
   ],
   "source": [
    "print(library_base_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78016/78035 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluation_list = {}\n",
    "evaluation_list[metrics.ACCURACY] = model.evaluate([X_test_cat, X_test_num, X_test_tfidf], pred_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InputLayer' object has no attribute 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7b01d48463e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m mc.add(features = [],\n\u001b[0;32m      2\u001b[0m        \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m        evaluation = evaluation_list )\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\modelchimp\\__init__.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, model, evaluation, features)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mmodel_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_relevant_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict_to_kv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deep_learning_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_layer_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_platform_library\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPlatformLibraryType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKERAS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\skumarravindran\\AppData\\Local\\Continuum\\Anaconda2\\envs\\py35gpu1\\lib\\site-packages\\modelchimp\\keras.py\u001b[0m in \u001b[0;36m_get_layer_info\u001b[1;34m(layers)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m   \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'InputLayer' object has no attribute 'tag'"
     ]
    }
   ],
   "source": [
    "mc.add(features = [],\n",
    "       model = model,\n",
    "       evaluation = evaluation_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
